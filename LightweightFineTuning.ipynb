{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eljandoubi/Copilot/blob/main/LightweightFineTuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf3f9130",
      "metadata": {
        "id": "bf3f9130"
      },
      "source": [
        "# Lightweight Fine-Tuning Project"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e3f7aa6",
      "metadata": {
        "id": "6e3f7aa6"
      },
      "source": [
        "* PEFT technique: LoftQ initialization & QLoRA-style training\n",
        "* Model: GPT-2\n",
        "* Evaluation approach: Perplexity\n",
        "* Fine-tuning dataset: codeparrot/github-code"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8P8iWpw_6YRb",
        "outputId": "b29251b3-d220-4826-ea4c-3a29a5823d5b"
      },
      "id": "8P8iWpw_6YRb",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ipywidgets==8.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (8.1.1)\n",
            "Requirement already satisfied: notebook==7.0.7 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (7.0.7)\n",
            "Requirement already satisfied: datasets==2.16.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (2.16.1)\n",
            "Requirement already satisfied: transformers==4.37.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (4.37.2)\n",
            "Requirement already satisfied: accelerate==0.26.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (0.26.1)\n",
            "Requirement already satisfied: bitsandbytes==0.42.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (0.42.0)\n",
            "Requirement already satisfied: peft==0.8.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (0.8.1)\n",
            "Requirement already satisfied: torch==2.2.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (2.2.0)\n",
            "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==8.1.1->-r requirements.txt (line 1)) (0.2.1)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==8.1.1->-r requirements.txt (line 1)) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==8.1.1->-r requirements.txt (line 1)) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.9 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==8.1.1->-r requirements.txt (line 1)) (4.0.9)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.9 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==8.1.1->-r requirements.txt (line 1)) (3.0.9)\n",
            "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from notebook==7.0.7->-r requirements.txt (line 2)) (2.12.5)\n",
            "Requirement already satisfied: jupyterlab-server<3,>=2.22.1 in /usr/local/lib/python3.10/dist-packages (from notebook==7.0.7->-r requirements.txt (line 2)) (2.25.2)\n",
            "Requirement already satisfied: jupyterlab<5,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from notebook==7.0.7->-r requirements.txt (line 2)) (4.0.12)\n",
            "Requirement already satisfied: notebook-shim<0.3,>=0.2 in /usr/local/lib/python3.10/dist-packages (from notebook==7.0.7->-r requirements.txt (line 2)) (0.2.3)\n",
            "Requirement already satisfied: tornado>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from notebook==7.0.7->-r requirements.txt (line 2)) (6.3.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets==2.16.1->-r requirements.txt (line 3)) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets==2.16.1->-r requirements.txt (line 3)) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.16.1->-r requirements.txt (line 3)) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets==2.16.1->-r requirements.txt (line 3)) (0.6)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.16.1->-r requirements.txt (line 3)) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==2.16.1->-r requirements.txt (line 3)) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.16.1->-r requirements.txt (line 3)) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.16.1->-r requirements.txt (line 3)) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets==2.16.1->-r requirements.txt (line 3)) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets==2.16.1->-r requirements.txt (line 3)) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.16.1->-r requirements.txt (line 3)) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==2.16.1->-r requirements.txt (line 3)) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets==2.16.1->-r requirements.txt (line 3)) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets==2.16.1->-r requirements.txt (line 3)) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.16.1->-r requirements.txt (line 3)) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2->-r requirements.txt (line 4)) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2->-r requirements.txt (line 4)) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2->-r requirements.txt (line 4)) (0.4.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.26.1->-r requirements.txt (line 5)) (5.9.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes==0.42.0->-r requirements.txt (line 6)) (1.11.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->-r requirements.txt (line 8)) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->-r requirements.txt (line 8)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->-r requirements.txt (line 8)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->-r requirements.txt (line 8)) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->-r requirements.txt (line 8)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->-r requirements.txt (line 8)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->-r requirements.txt (line 8)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->-r requirements.txt (line 8)) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->-r requirements.txt (line 8)) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->-r requirements.txt (line 8)) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->-r requirements.txt (line 8)) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->-r requirements.txt (line 8)) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->-r requirements.txt (line 8)) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->-r requirements.txt (line 8)) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->-r requirements.txt (line 8)) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->-r requirements.txt (line 8)) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.0->-r requirements.txt (line 8)) (12.3.101)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.16.1->-r requirements.txt (line 3)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.16.1->-r requirements.txt (line 3)) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.16.1->-r requirements.txt (line 3)) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.16.1->-r requirements.txt (line 3)) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.16.1->-r requirements.txt (line 3)) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.16.1->-r requirements.txt (line 3)) (4.0.3)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.1.1->-r requirements.txt (line 1)) (67.7.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.1.1->-r requirements.txt (line 1)) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.1.1->-r requirements.txt (line 1)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.1.1->-r requirements.txt (line 1)) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.1.1->-r requirements.txt (line 1)) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.1.1->-r requirements.txt (line 1)) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.1.1->-r requirements.txt (line 1)) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.1.1->-r requirements.txt (line 1)) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.1.1->-r requirements.txt (line 1)) (4.9.0)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->notebook==7.0.7->-r requirements.txt (line 2)) (3.7.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->notebook==7.0.7->-r requirements.txt (line 2)) (23.1.0)\n",
            "Requirement already satisfied: jupyter-client>=7.4.4 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->notebook==7.0.7->-r requirements.txt (line 2)) (8.6.0)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->notebook==7.0.7->-r requirements.txt (line 2)) (5.7.1)\n",
            "Requirement already satisfied: jupyter-events>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->notebook==7.0.7->-r requirements.txt (line 2)) (0.9.0)\n",
            "Requirement already satisfied: jupyter-server-terminals in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->notebook==7.0.7->-r requirements.txt (line 2)) (0.5.2)\n",
            "Requirement already satisfied: nbconvert>=6.4.4 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->notebook==7.0.7->-r requirements.txt (line 2)) (6.5.4)\n",
            "Requirement already satisfied: nbformat>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->notebook==7.0.7->-r requirements.txt (line 2)) (5.9.2)\n",
            "Requirement already satisfied: overrides in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->notebook==7.0.7->-r requirements.txt (line 2)) (7.7.0)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->notebook==7.0.7->-r requirements.txt (line 2)) (0.19.0)\n",
            "Requirement already satisfied: pyzmq>=24 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->notebook==7.0.7->-r requirements.txt (line 2)) (25.1.2)\n",
            "Requirement already satisfied: send2trash>=1.8.2 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->notebook==7.0.7->-r requirements.txt (line 2)) (1.8.2)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->notebook==7.0.7->-r requirements.txt (line 2)) (0.18.0)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->notebook==7.0.7->-r requirements.txt (line 2)) (1.7.0)\n",
            "Requirement already satisfied: async-lru>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab<5,>=4.0.2->notebook==7.0.7->-r requirements.txt (line 2)) (2.0.4)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from jupyterlab<5,>=4.0.2->notebook==7.0.7->-r requirements.txt (line 2)) (5.5.6)\n",
            "Requirement already satisfied: jupyter-lsp>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab<5,>=4.0.2->notebook==7.0.7->-r requirements.txt (line 2)) (2.2.2)\n",
            "Requirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from jupyterlab<5,>=4.0.2->notebook==7.0.7->-r requirements.txt (line 2)) (2.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.2.0->-r requirements.txt (line 8)) (2.1.4)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.10/dist-packages (from jupyterlab-server<3,>=2.22.1->notebook==7.0.7->-r requirements.txt (line 2)) (2.14.0)\n",
            "Requirement already satisfied: json5>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab-server<3,>=2.22.1->notebook==7.0.7->-r requirements.txt (line 2)) (0.9.14)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab-server<3,>=2.22.1->notebook==7.0.7->-r requirements.txt (line 2)) (4.19.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.16.1->-r requirements.txt (line 3)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.16.1->-r requirements.txt (line 3)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.16.1->-r requirements.txt (line 3)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.16.1->-r requirements.txt (line 3)) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.16.1->-r requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.16.1->-r requirements.txt (line 3)) (2023.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.0->-r requirements.txt (line 8)) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook==7.0.7->-r requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook==7.0.7->-r requirements.txt (line 2)) (1.2.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets==8.1.1->-r requirements.txt (line 1)) (0.8.3)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook==7.0.7->-r requirements.txt (line 2)) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook==7.0.7->-r requirements.txt (line 2)) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook==7.0.7->-r requirements.txt (line 2)) (0.17.1)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-server<3,>=2.4.0->notebook==7.0.7->-r requirements.txt (line 2)) (4.2.0)\n",
            "Requirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.10/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook==7.0.7->-r requirements.txt (line 2)) (2.0.7)\n",
            "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.10/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook==7.0.7->-r requirements.txt (line 2)) (0.1.4)\n",
            "Requirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook==7.0.7->-r requirements.txt (line 2)) (0.1.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook==7.0.7->-r requirements.txt (line 2)) (4.9.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook==7.0.7->-r requirements.txt (line 2)) (4.12.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook==7.0.7->-r requirements.txt (line 2)) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook==7.0.7->-r requirements.txt (line 2)) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook==7.0.7->-r requirements.txt (line 2)) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook==7.0.7->-r requirements.txt (line 2)) (0.3.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook==7.0.7->-r requirements.txt (line 2)) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook==7.0.7->-r requirements.txt (line 2)) (0.9.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook==7.0.7->-r requirements.txt (line 2)) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook==7.0.7->-r requirements.txt (line 2)) (1.2.1)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->notebook==7.0.7->-r requirements.txt (line 2)) (2.19.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets==8.1.1->-r requirements.txt (line 1)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets==8.1.1->-r requirements.txt (line 1)) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets==2.16.1->-r requirements.txt (line 3)) (1.16.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->jupyter-server<3,>=2.4.0->notebook==7.0.7->-r requirements.txt (line 2)) (21.2.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyterlab<5,>=4.0.2->notebook==7.0.7->-r requirements.txt (line 2)) (0.2.0)\n",
            "Requirement already satisfied: fqdn in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook==7.0.7->-r requirements.txt (line 2)) (1.5.1)\n",
            "Requirement already satisfied: isoduration in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook==7.0.7->-r requirements.txt (line 2)) (20.11.0)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook==7.0.7->-r requirements.txt (line 2)) (2.4)\n",
            "Requirement already satisfied: uri-template in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook==7.0.7->-r requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: webcolors>=1.11 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook==7.0.7->-r requirements.txt (line 2)) (1.13)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->notebook==7.0.7->-r requirements.txt (line 2)) (1.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook==7.0.7->-r requirements.txt (line 2)) (2.5)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook==7.0.7->-r requirements.txt (line 2)) (0.5.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->notebook==7.0.7->-r requirements.txt (line 2)) (2.21)\n",
            "Requirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from isoduration->jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook==7.0.7->-r requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/lib/python3.10/dist-packages (from arrow>=0.15.0->isoduration->jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook==7.0.7->-r requirements.txt (line 2)) (2.8.19.20240106)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f20bf789",
      "metadata": {
        "id": "f20bf789"
      },
      "source": [
        "## Loading and Evaluating a Foundation Model\n",
        "\n",
        "In the cells below, I will load the pre-trained Hugging Face model and evaluate its performance prior to fine-tuning. This step includes loading an appropriate tokenizer and dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4598eee2",
      "metadata": {
        "id": "4598eee2"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "b789a0c2",
      "metadata": {
        "id": "b789a0c2"
      },
      "outputs": [],
      "source": [
        "train_size=1_000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ebf52adb",
      "metadata": {
        "id": "ebf52adb"
      },
      "outputs": [],
      "source": [
        "val_size=train_size//10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "b2c55ae4",
      "metadata": {
        "id": "b2c55ae4"
      },
      "outputs": [],
      "source": [
        "test_size=val_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "7687ef06",
      "metadata": {
        "id": "7687ef06"
      },
      "outputs": [],
      "source": [
        "seed=42"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I will load the dataset in streaming mode to avoid downloading the entire 1TB."
      ],
      "metadata": {
        "id": "poY-pIVXIGRD"
      },
      "id": "poY-pIVXIGRD"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ced74482",
      "metadata": {
        "id": "ced74482"
      },
      "outputs": [],
      "source": [
        "iter_ds=load_dataset(\"codeparrot/github-code\", streaming=True, trust_remote_code=True,\n",
        "                split=\"train\").shuffle(seed=seed,\n",
        "                                       buffer_size=train_size+val_size+test_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "36a5d650",
      "metadata": {
        "id": "36a5d650"
      },
      "outputs": [],
      "source": [
        "iter_train_ds=iter_ds.take(train_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "6eb60851",
      "metadata": {
        "id": "6eb60851"
      },
      "outputs": [],
      "source": [
        "iter_val_ds=iter_ds.skip(train_size).take(val_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "dc5c566b",
      "metadata": {
        "id": "dc5c566b"
      },
      "outputs": [],
      "source": [
        "iter_test_ds=iter_ds.skip(train_size+val_size).take(test_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "dac38f18",
      "metadata": {
        "id": "dac38f18"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "6d14a2f4",
      "metadata": {
        "id": "6d14a2f4"
      },
      "outputs": [],
      "source": [
        "model_id = \"gpt2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "5810fba9",
      "metadata": {
        "id": "5810fba9"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "eda3d146",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eda3d146",
        "outputId": "e0f2c4af-53a7-49e5-e254-090c0ca430ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "it was None\n"
          ]
        }
      ],
      "source": [
        "if tokenizer.pad_token is None:\n",
        "  print(\"it was None\")\n",
        "  tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "91c72362",
      "metadata": {
        "id": "91c72362"
      },
      "outputs": [],
      "source": [
        "from transformers import PreTrainedTokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I will segment the text so that it can be processed by the model within the context length."
      ],
      "metadata": {
        "id": "YiYpL-Q1IJUt"
      },
      "id": "YiYpL-Q1IJUt"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "3c8faa9a",
      "metadata": {
        "id": "3c8faa9a"
      },
      "outputs": [],
      "source": [
        "def chunk_and_encode(\n",
        "        samples: dict[str,  str],\n",
        "        tokenizer: PreTrainedTokenizer,\n",
        "        max_len: int,\n",
        "        stride: int,\n",
        "        col_name: str) -> dict[str, list[list[int]]]:\n",
        "    \"\"\"\n",
        "    Split test in chunks and encode them\n",
        "    Args:\n",
        "        samples (dict[str, str]):  batch of data raws from hugging face dataset\n",
        "        tokenizer (PreTrainedTokenizer): hugging face tokenizer\n",
        "        max_len (int): the length of chunk\n",
        "        stride (int): the number of overlapping tokens\n",
        "        col_name (str): the name of the text column\n",
        "    Return:\n",
        "        tokenized chunks (dict[str, list[list[int]]])\n",
        "    \"\"\"\n",
        "\n",
        "    chunks = []\n",
        "    chunks_mask = []\n",
        "    pad_id = tokenizer.pad_token_id\n",
        "\n",
        "    for text in samples[col_name]:\n",
        "        tokens = tokenizer(text, truncation=False,\n",
        "                           return_attention_mask=False,\n",
        "                           padding=False)['input_ids']\n",
        "\n",
        "        start_idx = 0\n",
        "        while start_idx < len(tokens):\n",
        "            end_idx = min(start_idx + max_len, len(tokens))\n",
        "            chunk = tokens[start_idx:end_idx]\n",
        "            len_chunk = len(chunk)\n",
        "            chunk += (max_len - len_chunk) * [pad_id]\n",
        "            attention_mask = [1] * len_chunk + (max_len - len_chunk) * [0]\n",
        "\n",
        "            chunks.append(chunk)\n",
        "            chunks_mask.append(attention_mask)\n",
        "\n",
        "            start_idx += stride\n",
        "    return {\n",
        "        'input_ids': chunks,\n",
        "        'attention_mask': chunks_mask\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "8b5b4bcd",
      "metadata": {
        "id": "8b5b4bcd"
      },
      "outputs": [],
      "source": [
        "max_length=2**10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "44ce57f5",
      "metadata": {
        "id": "44ce57f5"
      },
      "outputs": [],
      "source": [
        "stride=max_length//16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "d3804066",
      "metadata": {
        "id": "d3804066"
      },
      "outputs": [],
      "source": [
        "col_name=\"code\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "6c2703ac",
      "metadata": {
        "id": "6c2703ac"
      },
      "outputs": [],
      "source": [
        "from functools import partial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "83499b73",
      "metadata": {
        "id": "83499b73"
      },
      "outputs": [],
      "source": [
        "process_text = partial(chunk_and_encode,\n",
        "                tokenizer=tokenizer,\n",
        "                max_len=max_length,\n",
        "                stride=stride,\n",
        "                col_name=col_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "51b3474a",
      "metadata": {
        "id": "51b3474a"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset,IterableDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "bf634de7-84ac-4cfa-a8ad-5270cb96d820",
      "metadata": {
        "id": "bf634de7-84ac-4cfa-a8ad-5270cb96d820"
      },
      "outputs": [],
      "source": [
        "def gen_from_iterable_dataset(iterable_ds: IterableDataset)->dict:\n",
        "    \"\"\"Create a generator from an iterable dataset\"\"\"\n",
        "    yield from iterable_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "ca5101c6-3da5-40b4-bc35-faa3255b26c4",
      "metadata": {
        "id": "ca5101c6-3da5-40b4-bc35-faa3255b26c4"
      },
      "outputs": [],
      "source": [
        "def create_dataset(iterable_ds: IterableDataset)->Dataset:\n",
        "    \"\"\"Create a dataset from an iterable dataset\"\"\"\n",
        "    iter_token=iterable_ds.map(process_text,\n",
        "                              remove_columns=iter_ds.column_names,\n",
        "                              batched=True)\n",
        "    return Dataset.from_generator(partial(gen_from_iterable_dataset, iter_token))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "e23b182b",
      "metadata": {
        "id": "e23b182b"
      },
      "outputs": [],
      "source": [
        "train_ds=create_dataset(iter_train_ds).shuffle(seed=seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "54644c11-7de4-422c-93f8-9acb6118ec66",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54,
          "referenced_widgets": [
            "2a3019a1dcbc40ca82cee129648c651d",
            "bb3890f9922b4a4186376df84a7f3a78",
            "ad52029a1eae496fb948b68087842683",
            "f7ff00703e81478792689da4cfbe28bc",
            "3239704e1f47471288228bf1062b1262",
            "f6c08a1512f146de8a069444bddbf866",
            "99dc3e697fd34a89800990da70295e33",
            "b555d36288e74402ad06bbee0ad1c332",
            "cc9b7232449042ff9704c91c5c072049",
            "826d22996ec54e4f9472c3fcc01acff6",
            "51f762f3cc4449dabd6b77293a321309"
          ]
        },
        "id": "54644c11-7de4-422c-93f8-9acb6118ec66",
        "outputId": "1cc09536-5dd9-48a2-be74-8aebdce70d89"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2a3019a1dcbc40ca82cee129648c651d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (12599 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ],
      "source": [
        "val_ds=create_dataset(iter_val_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "41287f0c-2cdc-45d4-861c-143fe3bc0456",
      "metadata": {
        "id": "41287f0c-2cdc-45d4-861c-143fe3bc0456"
      },
      "outputs": [],
      "source": [
        "test_ds=create_dataset(iter_test_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I will load the model in NF4, as described in the QLoRA paper. The computation will be performed using Brain Float 16-bit precision."
      ],
      "metadata": {
        "id": "gPRV6SZ2KHYg"
      },
      "id": "gPRV6SZ2KHYg"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "cf4f842a",
      "metadata": {
        "id": "cf4f842a"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BitsAndBytesConfig\n",
        "\n",
        "config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        ")"
      ],
      "metadata": {
        "id": "uQYoGKNXrezk"
      },
      "id": "uQYoGKNXrezk",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM"
      ],
      "metadata": {
        "id": "3YmlQ8OLrzdw"
      },
      "id": "3YmlQ8OLrzdw",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "e61de881",
      "metadata": {
        "id": "e61de881"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"auto\", quantization_config=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "da478f8f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da478f8f",
        "outputId": "061527bd-6ce0-42f9-f6b8-0cbb63e8af18"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50257, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-11): 12 x GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Linear4bit(in_features=768, out_features=2304, bias=True)\n",
              "          (c_proj): Linear4bit(in_features=768, out_features=768, bias=True)\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Linear4bit(in_features=768, out_features=3072, bias=True)\n",
              "          (c_proj): Linear4bit(in_features=3072, out_features=768, bias=True)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee67a30f",
      "metadata": {
        "id": "ee67a30f"
      },
      "source": [
        "Perplexity (PPL) is one of the most common metrics for evaluating language models.\n",
        "\n",
        "It is defined as the exponentiated average negative log-likelihood of a sequence, calculated with exponent base `e`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "a69ce1a7",
      "metadata": {
        "id": "a69ce1a7"
      },
      "outputs": [],
      "source": [
        "from transformers import PreTrainedModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "e2bb3b6e",
      "metadata": {
        "id": "e2bb3b6e"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "e88061ae",
      "metadata": {
        "id": "e88061ae"
      },
      "outputs": [],
      "source": [
        "def evaluate(model: PreTrainedModel,\n",
        "             eval_ds: Dataset,\n",
        "             batch_size: int,\n",
        "            )->dict[str,float]:\n",
        "\n",
        "    \"\"\"\n",
        "    Compute the perplexity of a model over an evaluation dataset\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    losses = []\n",
        "    for batch in tqdm(eval_ds.iter(batch_size)):\n",
        "        input_ids=torch.LongTensor(batch[\"input_ids\"])\n",
        "        with torch.no_grad():\n",
        "            batch_loss = model(input_ids, labels=input_ids).loss.reshape(1,-1)\n",
        "\n",
        "        losses.append(batch_loss)\n",
        "    loss = torch.mean(torch.cat(losses))\n",
        "    try:\n",
        "        perplexity = torch.exp(loss).item()\n",
        "    except OverflowError:\n",
        "        perplexity = float(\"inf\")\n",
        "    return {\"perplexity\":perplexity}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=32"
      ],
      "metadata": {
        "id": "ruDRSmN3Ix6f"
      },
      "id": "ruDRSmN3Ix6f",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "89da212f",
      "metadata": {
        "id": "89da212f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "138ca6b5-15c9-4047-ef0c-43feb4e3a337"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "162it [16:06,  5.97s/it]\n"
          ]
        }
      ],
      "source": [
        "base_score=evaluate(model,test_ds,batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "b474fe72",
      "metadata": {
        "id": "b474fe72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6260d076-42ea-4d32-9d64-370f2d050e01"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'perplexity': 61.875}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "base_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "rRMWDSaoVt1I"
      },
      "id": "rRMWDSaoVt1I",
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f3db148d",
      "metadata": {
        "id": "f3db148d"
      },
      "source": [
        "## Performing Parameter-Efficient Fine-Tuning\n",
        "\n",
        "In the cells below, I will create a PEFT model from your loaded model, run a training loop, and save the PEFT model weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "3e92f8af",
      "metadata": {
        "id": "3e92f8af"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"auto\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "fb7f6534",
      "metadata": {
        "id": "fb7f6534",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2a7c442-c1eb-462a-e793-2595d426252d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50257, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-11): 12 x GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "38c8640c",
      "metadata": {
        "id": "38c8640c"
      },
      "outputs": [],
      "source": [
        "from peft import LoftQConfig, LoraConfig, get_peft_model, prepare_model_for_kbit_training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "949db024",
      "metadata": {
        "id": "949db024"
      },
      "outputs": [],
      "source": [
        "loftq_config = LoftQConfig(loftq_bits=4)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lora_config = LoraConfig(\n",
        "    init_lora_weights=\"loftq\",\n",
        "    loftq_config=loftq_config,\n",
        "    r=64,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"c_fc\", \"c_attn\", \"c_proj\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")"
      ],
      "metadata": {
        "id": "ETJ2Qrjc0WeH"
      },
      "id": "ETJ2Qrjc0WeH",
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_peft_model(model, lora_config)"
      ],
      "metadata": {
        "id": "E-swK20o0ppj"
      },
      "id": "E-swK20o0ppj",
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.print_trainable_parameters()"
      ],
      "metadata": {
        "id": "BUIRl7c_2BvX",
        "outputId": "8c3870f0-7e35-4124-f146-092191c36c62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "BUIRl7c_2BvX",
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 9,437,184 || all params: 133,876,992 || trainable%: 7.049145532041831\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "6nW2gu321IEB",
        "outputId": "f75360a6-6d8e-402b-bb9f-86bd4e1f46ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "6nW2gu321IEB",
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModelForCausalLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): GPT2LMHeadModel(\n",
              "      (transformer): GPT2Model(\n",
              "        (wte): Embedding(50257, 768)\n",
              "        (wpe): Embedding(1024, 768)\n",
              "        (drop): Dropout(p=0.1, inplace=False)\n",
              "        (h): ModuleList(\n",
              "          (0-11): 12 x GPT2Block(\n",
              "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): GPT2Attention(\n",
              "              (c_attn): lora.Linear(\n",
              "                (base_layer): Conv1D()\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=768, out_features=64, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=64, out_features=2304, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (c_proj): lora.Linear(\n",
              "                (base_layer): Conv1D()\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=768, out_features=64, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=64, out_features=768, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): GPT2MLP(\n",
              "              (c_fc): lora.Linear(\n",
              "                (base_layer): Conv1D()\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=768, out_features=64, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=64, out_features=3072, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (c_proj): lora.Linear(\n",
              "                (base_layer): Conv1D()\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3072, out_features=64, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=64, out_features=768, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (act): NewGELUActivation()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = prepare_model_for_kbit_training(model)"
      ],
      "metadata": {
        "id": "ZEcCUn091YM-"
      },
      "id": "ZEcCUn091YM-",
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForLanguageModeling"
      ],
      "metadata": {
        "id": "XOa3NknE5Lld"
      },
      "id": "XOa3NknE5Lld",
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
      ],
      "metadata": {
        "id": "3yCVWGBa2EE-"
      },
      "id": "3yCVWGBa2EE-",
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments"
      ],
      "metadata": {
        "id": "c-RBrxAG3GJ8"
      },
      "id": "c-RBrxAG3GJ8",
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "        f\"{model_id}-finetuned-lora\",\n",
        "        optim=\"paged_lion_8bit\",\n",
        "        learning_rate=5e-6,\n",
        "        weight_decay=0.01,\n",
        "        auto_find_batch_size=True,\n",
        "        gradient_accumulation_steps=4,\n",
        "        num_train_epochs=3,\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        dataloader_num_workers=16,\n",
        "        logging_steps=100,\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"eval_loss\",\n",
        "        push_to_hub=False,\n",
        "        greater_is_better=False,\n",
        "    )"
      ],
      "metadata": {
        "id": "fp0Z8HdR5PxE"
      },
      "id": "fp0Z8HdR5PxE",
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer"
      ],
      "metadata": {
        "id": "5rZ8eHhdA90N"
      },
      "id": "5rZ8eHhdA90N",
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset= val_ds,\n",
        "    data_collator=data_collator,\n",
        ")"
      ],
      "metadata": {
        "id": "u53rFXrLA1KU"
      },
      "id": "u53rFXrLA1KU",
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "nAeg-QF2Bgxf"
      },
      "id": "nAeg-QF2Bgxf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "9e995479",
      "metadata": {
        "id": "9e995479"
      },
      "source": [
        "## Performing Inference with a PEFT Model\n",
        "\n",
        "TODO: In the cells below, load the saved PEFT model weights and evaluate the performance of the trained PEFT model. Be sure to compare the results to the results from prior to fine-tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "031c10e7",
      "metadata": {
        "id": "031c10e7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "3ebd553d",
      "metadata": {
        "id": "3ebd553d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "294ff38c",
      "metadata": {
        "id": "294ff38c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "81dc501b",
      "metadata": {
        "id": "81dc501b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "a7b326f2",
      "metadata": {
        "id": "a7b326f2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2a3019a1dcbc40ca82cee129648c651d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bb3890f9922b4a4186376df84a7f3a78",
              "IPY_MODEL_ad52029a1eae496fb948b68087842683",
              "IPY_MODEL_f7ff00703e81478792689da4cfbe28bc"
            ],
            "layout": "IPY_MODEL_3239704e1f47471288228bf1062b1262",
            "tabbable": null,
            "tooltip": null
          }
        },
        "bb3890f9922b4a4186376df84a7f3a78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_f6c08a1512f146de8a069444bddbf866",
            "placeholder": "",
            "style": "IPY_MODEL_99dc3e697fd34a89800990da70295e33",
            "tabbable": null,
            "tooltip": null,
            "value": "Generating train split: "
          }
        },
        "ad52029a1eae496fb948b68087842683": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_b555d36288e74402ad06bbee0ad1c332",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cc9b7232449042ff9704c91c5c072049",
            "tabbable": null,
            "tooltip": null,
            "value": 1
          }
        },
        "f7ff00703e81478792689da4cfbe28bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_826d22996ec54e4f9472c3fcc01acff6",
            "placeholder": "",
            "style": "IPY_MODEL_51f762f3cc4449dabd6b77293a321309",
            "tabbable": null,
            "tooltip": null,
            "value": " 7411/0 [00:11&lt;00:00, 1184.64 examples/s]"
          }
        },
        "3239704e1f47471288228bf1062b1262": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6c08a1512f146de8a069444bddbf866": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99dc3e697fd34a89800990da70295e33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "b555d36288e74402ad06bbee0ad1c332": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "cc9b7232449042ff9704c91c5c072049": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "826d22996ec54e4f9472c3fcc01acff6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51f762f3cc4449dabd6b77293a321309": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}