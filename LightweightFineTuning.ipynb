{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eljandoubi/Copilot/blob/main/LightweightFineTuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf3f9130",
      "metadata": {
        "id": "bf3f9130"
      },
      "source": [
        "# Lightweight Fine-Tuning Project"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e3f7aa6",
      "metadata": {
        "id": "6e3f7aa6"
      },
      "source": [
        "* PEFT technique: LoftQ initialization & QLoRA-style training\n",
        "* Model: GPT-2\n",
        "* Evaluation approach: Perplexity\n",
        "* Fine-tuning dataset: codeparrot/github-code"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "8P8iWpw_6YRb"
      },
      "id": "8P8iWpw_6YRb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f20bf789",
      "metadata": {
        "id": "f20bf789"
      },
      "source": [
        "## Loading and Evaluating a Foundation Model\n",
        "\n",
        "In the cells below, I will load the pre-trained Hugging Face model and evaluate its performance prior to fine-tuning. This step includes loading an appropriate tokenizer and dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4598eee2",
      "metadata": {
        "id": "4598eee2"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b789a0c2",
      "metadata": {
        "id": "b789a0c2"
      },
      "outputs": [],
      "source": [
        "train_size=1_000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebf52adb",
      "metadata": {
        "id": "ebf52adb"
      },
      "outputs": [],
      "source": [
        "val_size=train_size//10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2c55ae4",
      "metadata": {
        "id": "b2c55ae4"
      },
      "outputs": [],
      "source": [
        "test_size=val_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7687ef06",
      "metadata": {
        "id": "7687ef06"
      },
      "outputs": [],
      "source": [
        "seed=42"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I will load the dataset in streaming mode to avoid downloading the entire 1TB."
      ],
      "metadata": {
        "id": "poY-pIVXIGRD"
      },
      "id": "poY-pIVXIGRD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ced74482",
      "metadata": {
        "id": "ced74482"
      },
      "outputs": [],
      "source": [
        "iter_ds=load_dataset(\"codeparrot/github-code\", streaming=True, trust_remote_code=True,\n",
        "                split=\"train\").shuffle(seed=seed,\n",
        "                                       buffer_size=train_size+val_size+test_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36a5d650",
      "metadata": {
        "id": "36a5d650"
      },
      "outputs": [],
      "source": [
        "iter_train_ds=iter_ds.take(train_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6eb60851",
      "metadata": {
        "id": "6eb60851"
      },
      "outputs": [],
      "source": [
        "iter_val_ds=iter_ds.skip(train_size).take(val_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc5c566b",
      "metadata": {
        "id": "dc5c566b"
      },
      "outputs": [],
      "source": [
        "iter_test_ds=iter_ds.skip(train_size+val_size).take(test_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dac38f18",
      "metadata": {
        "id": "dac38f18"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d14a2f4",
      "metadata": {
        "id": "6d14a2f4"
      },
      "outputs": [],
      "source": [
        "model_id = \"gpt2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5810fba9",
      "metadata": {
        "id": "5810fba9"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eda3d146",
      "metadata": {
        "id": "eda3d146"
      },
      "outputs": [],
      "source": [
        "if tokenizer.pad_token is None:\n",
        "  print(\"it was None\")\n",
        "  tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91c72362",
      "metadata": {
        "id": "91c72362"
      },
      "outputs": [],
      "source": [
        "from transformers import PreTrainedTokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I will segment the text so that it can be processed by the model within the context length."
      ],
      "metadata": {
        "id": "YiYpL-Q1IJUt"
      },
      "id": "YiYpL-Q1IJUt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c8faa9a",
      "metadata": {
        "id": "3c8faa9a"
      },
      "outputs": [],
      "source": [
        "def chunk_and_encode(\n",
        "        samples: dict[str,  str],\n",
        "        tokenizer: PreTrainedTokenizer,\n",
        "        max_len: int,\n",
        "        stride: int,\n",
        "        col_name: str) -> dict[str, list[list[int]]]:\n",
        "    \"\"\"\n",
        "    Split test in chunks and encode them\n",
        "    Args:\n",
        "        samples (dict[str, str]):  batch of data raws from hugging face dataset\n",
        "        tokenizer (PreTrainedTokenizer): hugging face tokenizer\n",
        "        max_len (int): the length of chunk\n",
        "        stride (int): the number of overlapping tokens\n",
        "        col_name (str): the name of the text column\n",
        "    Return:\n",
        "        tokenized chunks (dict[str, list[list[int]]])\n",
        "    \"\"\"\n",
        "\n",
        "    chunks = []\n",
        "    chunks_mask = []\n",
        "    pad_id = tokenizer.pad_token_id\n",
        "\n",
        "    for text in samples[col_name]:\n",
        "        tokens = tokenizer(text, truncation=False,\n",
        "                           return_attention_mask=False,\n",
        "                           padding=False)['input_ids']\n",
        "\n",
        "        start_idx = 0\n",
        "        while start_idx < len(tokens):\n",
        "            end_idx = min(start_idx + max_len, len(tokens))\n",
        "            chunk = tokens[start_idx:end_idx]\n",
        "            len_chunk = len(chunk)\n",
        "            chunk += (max_len - len_chunk) * [pad_id]\n",
        "            attention_mask = [1] * len_chunk + (max_len - len_chunk) * [0]\n",
        "\n",
        "            chunks.append(chunk)\n",
        "            chunks_mask.append(attention_mask)\n",
        "\n",
        "            start_idx += stride\n",
        "    return {\n",
        "        'input_ids': chunks,\n",
        "        'attention_mask': chunks_mask\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b5b4bcd",
      "metadata": {
        "id": "8b5b4bcd"
      },
      "outputs": [],
      "source": [
        "max_length=2**10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44ce57f5",
      "metadata": {
        "id": "44ce57f5"
      },
      "outputs": [],
      "source": [
        "stride=max_length//16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3804066",
      "metadata": {
        "id": "d3804066"
      },
      "outputs": [],
      "source": [
        "col_name=\"code\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c2703ac",
      "metadata": {
        "id": "6c2703ac"
      },
      "outputs": [],
      "source": [
        "from functools import partial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83499b73",
      "metadata": {
        "id": "83499b73"
      },
      "outputs": [],
      "source": [
        "process_text = partial(chunk_and_encode,\n",
        "                tokenizer=tokenizer,\n",
        "                max_len=max_length,\n",
        "                stride=stride,\n",
        "                col_name=col_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51b3474a",
      "metadata": {
        "id": "51b3474a"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset,IterableDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf634de7-84ac-4cfa-a8ad-5270cb96d820",
      "metadata": {
        "id": "bf634de7-84ac-4cfa-a8ad-5270cb96d820"
      },
      "outputs": [],
      "source": [
        "def gen_from_iterable_dataset(iterable_ds: IterableDataset)->dict:\n",
        "    \"\"\"Create a generator from an iterable dataset\"\"\"\n",
        "    yield from iterable_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca5101c6-3da5-40b4-bc35-faa3255b26c4",
      "metadata": {
        "id": "ca5101c6-3da5-40b4-bc35-faa3255b26c4"
      },
      "outputs": [],
      "source": [
        "def create_dataset(iterable_ds: IterableDataset)->Dataset:\n",
        "    \"\"\"Create a dataset from an iterable dataset\"\"\"\n",
        "    iter_token=iterable_ds.map(process_text,\n",
        "                              remove_columns=iter_ds.column_names,\n",
        "                              batched=True)\n",
        "    return Dataset.from_generator(partial(gen_from_iterable_dataset, iter_token))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e23b182b",
      "metadata": {
        "id": "e23b182b"
      },
      "outputs": [],
      "source": [
        "train_ds=create_dataset(iter_train_ds).shuffle(seed=seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54644c11-7de4-422c-93f8-9acb6118ec66",
      "metadata": {
        "id": "54644c11-7de4-422c-93f8-9acb6118ec66"
      },
      "outputs": [],
      "source": [
        "val_ds=create_dataset(iter_val_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41287f0c-2cdc-45d4-861c-143fe3bc0456",
      "metadata": {
        "id": "41287f0c-2cdc-45d4-861c-143fe3bc0456"
      },
      "outputs": [],
      "source": [
        "test_ds=create_dataset(iter_test_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I will load the model in NF4, as described in the QLoRA paper. The computation will be performed using Brain Float 16-bit precision."
      ],
      "metadata": {
        "id": "gPRV6SZ2KHYg"
      },
      "id": "gPRV6SZ2KHYg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf4f842a",
      "metadata": {
        "id": "cf4f842a"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BitsAndBytesConfig\n",
        "\n",
        "config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        ")"
      ],
      "metadata": {
        "id": "uQYoGKNXrezk"
      },
      "id": "uQYoGKNXrezk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM"
      ],
      "metadata": {
        "id": "3YmlQ8OLrzdw"
      },
      "id": "3YmlQ8OLrzdw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e61de881",
      "metadata": {
        "id": "e61de881"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"auto\", quantization_config=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da478f8f",
      "metadata": {
        "id": "da478f8f"
      },
      "outputs": [],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee67a30f",
      "metadata": {
        "id": "ee67a30f"
      },
      "source": [
        "Perplexity (PPL) is one of the most common metrics for evaluating language models.\n",
        "\n",
        "It is defined as the exponentiated average negative log-likelihood of a sequence, calculated with exponent base `e`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a69ce1a7",
      "metadata": {
        "id": "a69ce1a7"
      },
      "outputs": [],
      "source": [
        "from transformers import PreTrainedModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2bb3b6e",
      "metadata": {
        "id": "e2bb3b6e"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e88061ae",
      "metadata": {
        "id": "e88061ae",
        "outputId": "473342b8-0765-45dd-f6bc-e8d8b5b98288",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'PreTrainedModel' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-2bc3321251b9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m def evaluate(model: PreTrainedModel,\n\u001b[0m\u001b[1;32m      2\u001b[0m              \u001b[0meval_ds\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m              \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             )->dict[str,float]:\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'PreTrainedModel' is not defined"
          ]
        }
      ],
      "source": [
        "def evaluate(model: PreTrainedModel,\n",
        "             eval_ds: Dataset,\n",
        "             batch_size: int,\n",
        "            )->dict[str,float]:\n",
        "\n",
        "    \"\"\"\n",
        "    Compute the perplexity of a model over an evaluation dataset\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    losses = []\n",
        "    for batch in tqdm(eval_ds.iter(batch_size)):\n",
        "        input_ids=torch.LongTensor(batch[\"input_ids\"])\n",
        "        with torch.no_grad():\n",
        "            batch_loss = model(input_ids, labels=input_ids).loss.reshape(1,-1)\n",
        "\n",
        "        losses.append(batch_loss)\n",
        "    loss = torch.mean(torch.cat(losses))\n",
        "    try:\n",
        "        perplexity = torch.exp(loss).item()\n",
        "    except OverflowError:\n",
        "        perplexity = float(\"inf\")\n",
        "    return {\"perplexity\":perplexity}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=64"
      ],
      "metadata": {
        "id": "ruDRSmN3Ix6f"
      },
      "id": "ruDRSmN3Ix6f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89da212f",
      "metadata": {
        "id": "89da212f"
      },
      "outputs": [],
      "source": [
        "base_score=evaluate(model,test_ds,batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b474fe72",
      "metadata": {
        "id": "b474fe72"
      },
      "outputs": [],
      "source": [
        "base_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "rRMWDSaoVt1I"
      },
      "id": "rRMWDSaoVt1I",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f3db148d",
      "metadata": {
        "id": "f3db148d"
      },
      "source": [
        "## Performing Parameter-Efficient Fine-Tuning\n",
        "\n",
        "In the cells below, I will create a PEFT model from your loaded model, run a training loop, and save the PEFT model weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e92f8af",
      "metadata": {
        "id": "3e92f8af"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"auto\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb7f6534",
      "metadata": {
        "id": "fb7f6534"
      },
      "outputs": [],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38c8640c",
      "metadata": {
        "id": "38c8640c"
      },
      "outputs": [],
      "source": [
        "from peft import LoftQConfig, LoraConfig, get_peft_model, prepare_model_for_kbit_training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "949db024",
      "metadata": {
        "id": "949db024"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "9e995479",
      "metadata": {
        "id": "9e995479"
      },
      "source": [
        "## Performing Inference with a PEFT Model\n",
        "\n",
        "TODO: In the cells below, load the saved PEFT model weights and evaluate the performance of the trained PEFT model. Be sure to compare the results to the results from prior to fine-tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "031c10e7",
      "metadata": {
        "id": "031c10e7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ebd553d",
      "metadata": {
        "id": "3ebd553d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "294ff38c",
      "metadata": {
        "id": "294ff38c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81dc501b",
      "metadata": {
        "id": "81dc501b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7b326f2",
      "metadata": {
        "id": "a7b326f2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}